# -*- coding: utf-8 -*-
"""Untitled11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OgoikJ53I9TQ0TOii2ikciDJ0aGYYSQ8
"""

!pip uninstall -y pillow
!pip install pillow==10.2.0 --force-reinstall --no-cache-dir
!pip install gradio facenet-pytorch torch torchvision joblib gdown pillow numpy scikit-learn -q

!pip install facenet-pytorch

import os
import numpy as np
import torch
from facenet_pytorch import InceptionResnetV1
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from PIL import Image
import torchvision.transforms as transforms
import joblib
from collections import Counter

import kagglehub
import tarfile
import os


path = kagglehub.dataset_download("atulanandjha/lfwpeople")
print("‚úÖ Dataset downloaded to:", path)

tgz_path = os.path.join(path, "lfw-funneled.tgz")

extract_path = "/kaggle/working/lfw_funneled"

with tarfile.open(tgz_path, "r:gz") as tar:
    tar.extractall(path=extract_path)

print("‚úÖ Extraction done!")
print("üìÇ Number of folders:", len(os.listdir(extract_path)))
print("üìÇ First 5 people:", os.listdir(extract_path)[:5])

import torch
from facenet_pytorch import InceptionResnetV1
import torchvision.transforms as transforms
from PIL import Image
import numpy as np


# Use GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("‚úÖ Using device:", device)

# Load FaceNet
facenet = InceptionResnetV1(pretrained="vggface2").eval().to(device)

# Required transforms
transform = transforms.Compose([
    transforms.Resize((160, 160)),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

def get_embedding(image_pil):
    img_tensor = transform(image_pil).unsqueeze(0).to(device)
    with torch.no_grad():
        emb = facenet(img_tensor)
    return emb.squeeze(0).cpu().numpy()

X, y = [], []

lfw_root = os.path.join(extract_path, "lfw_funneled")

for person in os.listdir(lfw_root):
    person_folder = os.path.join(lfw_root, person)
    if not os.path.isdir(person_folder):
        continue

    for img_name in os.listdir(person_folder):
        img_path = os.path.join(person_folder, img_name)
        if os.path.isfile(img_path):
            try:
                img = Image.open(img_path).convert("RGB")
                emb = get_embedding(img)
                X.append(emb)
                y.append(person)
            except Exception as e:
                print("‚ùå Error with:", img_path, e)

X = np.array(X)
y = np.array(y)

print("‚úÖ Number of embeddings:", X.shape)
print("‚úÖ Number of people:", len(set(y)))

import numpy as np
from collections import Counter
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import joblib


counts = Counter(y)
mask = np.array([counts[label] > 1 for label in y])

X_filtered = X[mask]
y_filtered = y[mask]

print("‚úÖ After filtering:")
print("Number of images:", X_filtered.shape[0])
print("Number of people:", len(set(y_filtered)))


X_train, X_test, y_train, y_test = train_test_split(
    X_filtered, y_filtered, test_size=0.2, random_state=42, stratify=y_filtered
)

classifier = SVC(kernel="linear", probability=True)
classifier.fit(X_train, y_train)

joblib.dump(classifier, "classifier.pkl")
print("‚úÖ Model trained and saved as classifier.pkl")


y_pred = classifier.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"üìä Accuracy on test set: {acc*100:.2f}%")

print("\nüìë Classification Report (first 20 classes):")
print(classification_report(y_test, y_pred, labels=np.unique(y_test)[:20]))

counts = Counter(y)
mask = np.array([counts[label] > 1 for label in y])

X_filtered = X[mask]
y_filtered = y[mask]

print("‚úÖ After filtering:")
print("Number of images:", X_filtered.shape[0])
print("Number of persons:", len(set(y_filtered)))



X_train, X_test, y_train, y_test = train_test_split(
    X_filtered, y_filtered, test_size=0.2, random_state=42, stratify=y_filtered
)


classifier = SVC(kernel="linear", probability=True)
classifier.fit(X_train, y_train)


joblib.dump(classifier, "classifier.pkl")
print("‚úÖ Model trained and saved as classifier.pkl")


y_pred = classifier.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print(f"üìä Accuracy on test set: {acc*100:.2f}%")

print("\nüìë Classification Report (first 20 classes):")
print(classification_report(y_test, y_pred, labels=np.unique(y_test)[:20]))

import os
import random
from PIL import Image

lfw_root = os.path.join(extract_path, "lfw_funneled")


rand_idx = random.randint(0, len(X_test)-1)
true_person = y_test[rand_idx]


person_folder = os.path.join(lfw_root, true_person)
if not os.path.exists(person_folder):
  raise FileNotFoundError(f"‚ùå Person {true_person} not found in {lfw_root}")

img_name = random.choice(os.listdir(person_folder))
test_img_path = os.path.join(person_folder, img_name)


test_img = Image.open(test_img_path).convert("RGB")
test_emb = get_embedding(test_img).reshape(1, -1)

pred = classifier.predict(test_emb)[0]
proba = classifier.predict_proba(test_emb).max()

print("üñºÔ∏è Test image path:", test_img_path)
print("üñºÔ∏è True person:", true_person)
print("üîç Predicted:", pred)

import gradio as gr

from facenet_pytorch import MTCNN, InceptionResnetV1
import joblib
import gdown


# -----------------------------
# Automatically download the trained model if not found
# -----------------------------
MODEL_PATH = "classifier.pkl"
if not os.path.exists(MODEL_PATH):
    gdown.download("https://drive.google.com/uc?id=1tYcltIFwMc6lx1f4z5ZkDcIpy6eETz3R", MODEL_PATH, quiet=False)

classifier = joblib.load(MODEL_PATH)

# -----------------------------
# Initialize FaceNet and MTCNN
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
mtcnn = MTCNN(keep_all=False, device=device)
facenet = InceptionResnetV1(pretrained='vggface2').eval().to(device)

# -----------------------------
# Function to extract face embeddings and recognize the person
# -----------------------------
def recognize(image):
    if image is None:
        return "‚ùå No image uploaded"
    img = image.convert("RGB")
    face = mtcnn(img)
    if face is None:
        return "‚ùå No face detected"
    with torch.no_grad():
        embedding = facenet(face.unsqueeze(0).to(device)).detach().cpu().numpy()
    pred = classifier.predict(embedding)[0]
    return f"‚úÖ Person recognized: {pred}"

# -----------------------------
# Gradio Interface
# -----------------------------
demo = gr.Interface(
    fn=recognize,
    inputs=gr.Image(type="pil", label="Upload a face image"),
    outputs="text",
    title="Face Recognition App",
    description="Upload a photo and see who it is!"
)

demo.launch(share=True)